{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d27ae013-54bf-4936-9fa0-394f4dab36de",
   "metadata": {},
   "source": [
    "### working with Lemmatization and Stemming Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2763f1d8-d939-417e-a626-74307d1e0a30",
   "metadata": {},
   "source": [
    " **Stemming Technique is technique of reducing the word to its root word (stem)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b5915c-fcbe-4d81-bd4c-7909b55a92aa",
   "metadata": {},
   "source": [
    "**Eg: Running -> run, Eating -> eat, eaten -> eat**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8180df-c9a2-49f8-be2b-3790e03fe25a",
   "metadata": {},
   "source": [
    "#### Rule Based Stemming | Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ed4e92-3b40-4387-a868-d7e45f3ea7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "print(ps.stem('running'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7353dc7-1ec3-4e55-ab7c-924fa1e59a28",
   "metadata": {},
   "source": [
    "#### Dictionary Based : Different Forms of verbs have different key but stem word remains same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cbc2ed6-eebf-46ea-8f66-d48a6979ca1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "dictionary = {'running':'run','ran':'run','runner':'run'}\n",
    "word = 'running'\n",
    "print(dictionary.get(word,word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99273609-2b4b-4812-ac65-3e63be17a3ad",
   "metadata": {},
   "source": [
    "#### Corpus Based Stemming Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e174fe-4d50-4743-8e79-151bbe78c1e9",
   "metadata": {},
   "source": [
    "**It will pick up the word on the basis of the frequency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403e614c-915d-4611-b752-c2538a5700e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "forms = {'run':50,'running':30,'ran':20}\n",
    "stem =  max(forms,key=forms.get)\n",
    "print(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac0e61a-47b5-4656-b745-4b31cf302acc",
   "metadata": {},
   "source": [
    "#### Hybrid Stemming Technique : Prefined Technique with Custom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa2b830-dbee-4f71-a273-5314cd0e9e77",
   "metadata": {},
   "source": [
    "**Predefined**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f590ee32-4756-4c86-9e47-13fe65c521db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c8d7cc-723f-4e7b-89ff-66e9980e38ec",
   "metadata": {},
   "source": [
    "**Custom Technique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96101fe-697d-4f0d-bb44-a77422d28bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {'running':'run'}\n",
    "word = 'running'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a606d744-6385-42d7-b97f-1c58491ae49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.get(word,word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0bc9e-cc65-4249-ad8d-e84e72db124c",
   "metadata": {},
   "source": [
    "#### Merging Both Predefined Algorithm + Customer Technique = Hybrid Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de049fad-8556-46cd-bbe4-50ff72032d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "if word in dictionary:\n",
    "    stem = dictionary[word]\n",
    "else:\n",
    "    stem = ps.stem(word)\n",
    "print(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c911b-baf5-497a-81f5-562afe9f9da6",
   "metadata": {},
   "source": [
    "#### Light Stemming Technique : we try to find stem word on basis of some prefix or suffix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c127eeb-7098-4d07-ad5d-a19277ac1da1",
   "metadata": {},
   "source": [
    "**suffix : post of the word**\n",
    "**prefix : pre of the word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2ed1a8d-635b-4e37-a777-3be8e3aefd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"ing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e569ff9-2ad3-41c7-902e-4c450431ae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a92537d8-74d0-4cf0-94ce-eccecfbbd3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3c05549-e7ec-4ce8-9436-b420f49bf9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the word: eating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light Stemming: eat\n"
     ]
    }
   ],
   "source": [
    "word = input('Enter the word:')\n",
    "if word.endswith(suffix):\n",
    "   stem = word[:l]\n",
    "else:\n",
    "    stem = word\n",
    "print('Light Stemming:',stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "890efb48-17b3-4df4-91d8-81a2ef408afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the word: running\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light Stemming: run\n"
     ]
    }
   ],
   "source": [
    "word = input('Enter the word:')\n",
    "if word.endswith(suffix):\n",
    "   stem = word[:l]\n",
    "else:\n",
    "    stem = word\n",
    "print('Light Stemming:',stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f9b64-a36c-440e-9c53-e43237ac664b",
   "metadata": {},
   "source": [
    "#### Langauge-specific Morphological Stemming (Hindi Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e6e33b-df57-4278-b6f3-160c7e92c0ba",
   "metadata": {},
   "source": [
    "**running -> Hindi form -> chalna**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34dc7fc-530a-4207-8448-b9aa5e817641",
   "metadata": {},
   "source": [
    "**Indicnlp used for Hindi NLP Techniques :\n",
    "https://github.com/anoopkunchukuttan/indic_nlp_library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f65a0512-7c03-4f61-8a7c-24409e43b736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ladki\n"
     ]
    }
   ],
   "source": [
    "word = \"ladkiyon\" # girls\n",
    "suffix = \"yon\"\n",
    "l = len(suffix)\n",
    "stem = word[:-1*l] if word.endswith(suffix) else word\n",
    "print(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b35194-ebde-4a81-97cc-16be28700adc",
   "metadata": {},
   "source": [
    "#### Stemming Algorithms \n",
    " - Porter Stemmer\n",
    " - Snowball Stemmer\n",
    " - LanCaster Stemmer\n",
    "\n",
    "**Example**\n",
    "```word => running => Porter => run, snowball => run,lancaster=> run \n",
    "flies => porter => fli => fli => fli \n",
    "happily => happili => happi => happy \n",
    "fishing => fish => fish => fish\n",
    "better => better => better => bet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6affa4ff-97b9-4852-abbc-89463572dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer,SnowballStemmer,LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aacdea0d-7d0f-44c5-997b-a134345dfc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "sb = SnowballStemmer('english') # Snowball stemmer takes english as langauge\n",
    "lc = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18e8c9c7-6aef-48eb-9f80-d4f014fe6823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " word                 Porter               Snowball             Lancaster           \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "words = ['running','flies','happily','fishing','better']\n",
    "print(f\" {'word':<20} {'Porter':<20} {'Snowball':<20} {'Lancaster':<20}\")\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c25ddfe8-7cf5-479f-aecb-0cb3e80521e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " word                 Porter               Snowball             Lancaster           \n",
      "--------------------------------------------------------------------------------\n",
      " running              run                  run                  run                 \n",
      " flies                fli                  fli                  fli                 \n",
      " happily              happili              happili              happy               \n",
      " fishing              fish                 fish                 fish                \n",
      " better               better               better               bet                 \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\" {'word':<20} {'Porter':<20} {'Snowball':<20} {'Lancaster':<20}\")\n",
    "print(\"-\"*80)\n",
    "## use for loop to print the output\n",
    "for w in words:\n",
    "    print(f\" {w:<20} {ps.stem(w):<20} {sb.stem(w):<20} {lc.stem(w):<20}\")\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c432a85-c53b-434d-8569-3c190fe40cac",
   "metadata": {},
   "source": [
    "Problem with Stemming technique, is some algorithm work very fine for few words but for few words\n",
    "it do not work hence we must go more advance nlp technique which is called **Lemmatization**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7c1d73-5bb0-45a4-b35d-96cd1ab9923f",
   "metadata": {},
   "source": [
    "#### Lemmatization Technique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ffb9462-2b62-4232-b2eb-85ebe330ff53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Imart\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "734370e4-84ef-4bef-a942-01e378f854d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize('running',pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d61d20a6-ab52-4ae5-9dbc-ce77745bacac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happily\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize('happily',pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f962d01-e9a8-431e-88b4-101d01aa33f4",
   "metadata": {},
   "source": [
    "#### POS => Part of Speech\n",
    "\n",
    "1. verb => pos => v\n",
    "2. adverb => pos =>r\n",
    "3. adjective => a\n",
    "4. noun => n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f116cbbf-7c02-41e3-9b29-1905056a95ee",
   "metadata": {},
   "source": [
    "#### Lemmatization Technique with POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c06e693e-8054-4ddd-aaa3-c685c5889c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd6671b-81cf-402b-bfce-3d04b55234b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [('running','v'),('happily','r'),('better','a'),('geese','n'),('mice','n'),('congratulations','n'),('happiest','a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8d57fa6-6da5-4a47-9204-4e816950a7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('running', 'v'), ('happily', 'r'), ('better', 'a'), ('geese', 'n'), ('mice', 'n'), ('congratulations', 'n'), ('happiest', 'a')]\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1a694e5-ef98-45af-afdd-534e2871a106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word = running v => run\n",
      "word = happily r => happily\n",
      "word = better a => good\n",
      "word = geese n => goose\n",
      "word = mice n => mouse\n",
      "word = congratulations n => congratulation\n",
      "word = happiest a => happy\n"
     ]
    }
   ],
   "source": [
    "for word,pos in words:\n",
    "    lemma = lemmatizer.lemmatize(word,pos=pos)\n",
    "    print(f'word = {word} {pos} => {lemma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58b54c-6e52-432d-843b-e1df6d6132bf",
   "metadata": {},
   "source": [
    "#### Postagging is called part of speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc1c633-49d2-4ce2-9acd-70696d616943",
   "metadata": {},
   "source": [
    "**postagging can be used ofr Morphological(many forms) and Lexical Analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a83d0f-d21b-43bd-b772-c97b51486813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e253b56-15ba-4ab2-9b8c-2225c6bcfd55",
   "metadata": {},
   "source": [
    "#### in order to use POS Tagging we use averaged_perceptron_tagger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307e0e86-5e02-46b9-afbd-78ca86eb7e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Imart\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a806d043-5903-4d8d-8cae-d0568e19445e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Sunny', 'NNP'), ('Said', 'NNP'), ('Love', 'NNP'), ('you', 'PRP'), ('awnish', 'JJ'), ('hence', 'RB'), ('awnish', 'JJ'), ('started', 'VBD'), ('dancing', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "tags = nltk.pos_tag(word_tokenize(\"Sunny Said Love you awnish hence awnish started dancing\"))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dee54d-f05b-4c59-a29b-b3a878587fad",
   "metadata": {},
   "source": [
    "\"The\" is tagged as determiner (DT)\n",
    "\"quick\" is tagged as adjective (JJ)\n",
    "\"brown\" is tagged as adjective (JJ)\n",
    "\"fox\" is tagged as noun (NN)\n",
    "\"jumps\" is tagged as verb (VBZ)\n",
    "\"over\" is tagged as preposition (IN)\n",
    "\"the\" is tagged as determiner (DT)\n",
    "\"lazy\" is tagged as adjective (JJ)\n",
    "\"dog\" is tagged as noun (NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c61e5-4658-4fb1-b2bf-61171369381b",
   "metadata": {},
   "source": [
    "#### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c33c8-dc17-4ba1-9a0c-d7a59e33ccd9",
   "metadata": {},
   "source": [
    "**it is used to detect people, organisation and locations : Generate Parse Trees on Name Entity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5126ac6f-2e5c-47bd-be30-f2636edac885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Sunny', 'NNP'), ('Said', 'NNP'), ('Love', 'NNP'), ('you', 'PRP'), ('awnish', 'JJ'), ('hence', 'RB'), ('awnish', 'JJ'), ('started', 'VBD'), ('dancing', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "tags = nltk.pos_tag(word_tokenize(\"Sunny Said Love you awnish hence awnish started dancing\"))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5310af52-e758-40ad-a7c1-35ad3cf6cbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     C:\\Users\\Imart\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Imart\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082386ca-74b1-4d8c-8792-df1fa3b07f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "580a1cc1-e043-4228-950e-11d9cb4ef930",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ne_chunk(tags)\n",
    "tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c57144-b969-4e5c-820b-f2d68fc6c4f8",
   "metadata": {},
   "source": [
    "#### chunking => context Free Grammer => format => meaning information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cc6af71-ea1d-4bf0-9067-4e88c5be0ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import RegexpParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6af26a92-398c-4b76-834f-f920f7d180a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammer = \"NP:{<DT>?<JJ>*<NN>}\"\n",
    "cp = RegexpParser(grammer)\n",
    "result = cp.parse(tags)\n",
    "result.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0354997-aa88-4a6e-afc0-988e20a50237",
   "metadata": {},
   "source": [
    "#### Probability and Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e49a447-9de4-4e88-9087-b28d58ec29f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "words = word_tokenize(\"Sunny Said Love you awnish hence awnish started dancing\")\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ad2ec2-9feb-4688-875b-11540d9da52a",
   "metadata": {},
   "source": [
    "#### Plotting the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e956831-e882-4fcc-ad83-6bdc4b412528",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The plot function requires matplotlib to be installed.See https://matplotlib.org/",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Training\\spi\\Python-with-Datascience\\nlp\\myenv\\Lib\\site-packages\\nltk\\probability.py:268\u001b[39m, in \u001b[36mFreqDist.plot\u001b[39m\u001b[34m(self, title, cumulative, percents, show, *args, **kwargs)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mfdist\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Training\\spi\\Python-with-Datascience\\nlp\\myenv\\Lib\\site-packages\\nltk\\probability.py:270\u001b[39m, in \u001b[36mFreqDist.plot\u001b[39m\u001b[34m(self, title, cumulative, percents, show, *args, **kwargs)\u001b[39m\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    271\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe plot function requires matplotlib to be installed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    272\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSee https://matplotlib.org/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    273\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) == \u001b[32m0\u001b[39m:\n\u001b[32m    276\u001b[39m     args = [\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)]\n",
      "\u001b[31mValueError\u001b[39m: The plot function requires matplotlib to be installed.See https://matplotlib.org/"
     ]
    }
   ],
   "source": [
    "pip \n",
    "fdist.plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7272256-8973-4dc3-8ad4-247e844b877c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
